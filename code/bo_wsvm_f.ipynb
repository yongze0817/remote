{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical, Space\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import json\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\"自定义JSON编码器，用于处理numpy数据类型\"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NumpyEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ess(Y, W, X, alpha, support_indices):\n",
    "        weights = np.zeros(X.shape[0])\n",
    "        weights[support_indices] = np.abs(alpha)\n",
    "        alpha = weights / np.sum(weights)\n",
    "        \n",
    "        treated_ess = (np.sum(alpha[W == 1]))**2 / np.sum(alpha[W == 1]**2)\n",
    "        control_ess = (np.sum(alpha[W == -1]))**2 / np.sum(alpha[W == -1]**2)\n",
    "\n",
    "        return treated_ess + control_ess\n",
    "    \n",
    "def estimate_diff(Y, W, X, alpha, support_indices):\n",
    "\n",
    "    # 计算权重\n",
    "    weights = np.zeros(X.shape[0])\n",
    "    weights[support_indices] = np.abs(alpha)\n",
    "    alpha = weights / np.sum(weights)\n",
    "    \n",
    "    treated_mean = np.mean(Y[W == 1])\n",
    "    control_mean = np.mean(Y[W == -1])\n",
    "    \n",
    "    treated_std = np.std(Y[W == 1], ddof=1)\n",
    "    control_std = np.std(Y[W == -1], ddof=1)\n",
    "\n",
    "    normed_diff = np.abs(treated_mean - control_mean) / np.sqrt((treated_std**2 + control_std**2) / 2)\n",
    "\n",
    "    return normed_diff\n",
    "\n",
    "def estimate_ate(Y, W, X, alpha, support_indices):\n",
    "    \n",
    "    # 计算权重\n",
    "    weights = np.zeros(X.shape[0])\n",
    "    weights[support_indices] = np.abs(alpha)\n",
    "    alpha = weights / np.sum(weights)\n",
    "    \n",
    "    treated_mean = np.sum(Y[W == 1] * alpha[W == 1]) / np.sum(alpha[W == 1])\n",
    "    control_mean = np.sum(Y[W == -1] * alpha[W == -1]) / np.sum(alpha[W == -1])\n",
    "    return treated_mean - control_mean\n",
    "\n",
    "\n",
    "\n",
    "def compute_wnayman(Y_obs, W, X, alpha, support_indices):\n",
    "    \n",
    "    # 计算权重\n",
    "    weights = np.zeros(X.shape[0])\n",
    "    weights[support_indices] = np.abs(alpha)\n",
    "    lambda_i = weights / np.sum(weights)\n",
    "    \n",
    "    # 计算mu_c(x)和mu_t(x)，这里需要根据具体数据进行定义\n",
    "    mu_c = np.mean(Y_obs[W == -1])\n",
    "    mu_t = np.mean(Y_obs[W == 1])\n",
    "\n",
    "    # 计算sigma_c^2(x)和sigma_t^2(x)，这里需要根据具体数据进行定义\n",
    "    sigma_c_squared = np.var(Y_obs[W == -1])\n",
    "    sigma_t_squared = np.var(Y_obs[W == 1])\n",
    "\n",
    "    # 计算mu_i和sigma_i^2\n",
    "    mu_i = np.where(W == -1, mu_c, mu_t)\n",
    "    sigma_i_squared = np.where(W == -1, sigma_c_squared, sigma_t_squared)\n",
    "\n",
    "    N_t = np.sum(W == 1)\n",
    "    N_c = np.sum(W == -1)\n",
    "\n",
    "    # 计算条件抽样方差\n",
    "    conditional_variance = np.sum(lambda_i[W == 1]**2 * sigma_i_squared[W == 1]) + np.sum(lambda_i[W == -1]**2 * sigma_i_squared[W == -1])\n",
    "    \n",
    "    stderr = np.sqrt(conditional_variance)\n",
    "\n",
    "\n",
    "    print(\"条件抽样方差:\", conditional_variance)\n",
    "    return stderr\n",
    "\n",
    "class ConvergenceStopper:\n",
    "    def __init__(self, patience=10, tol=1e-6):\n",
    "        self.patience = patience\n",
    "        self.tol = tol\n",
    "        self.best_value = np.inf\n",
    "        self.no_improvement = 0\n",
    "    \n",
    "    def __call__(self, result):\n",
    "        if len(result.x_iters) < 10:  # 至少10个点才开始检查\n",
    "            return False\n",
    "        \n",
    "        current_min = np.min(result.func_vals)\n",
    "        \n",
    "        if self.best_value - current_min > self.tol:\n",
    "            self.best_value = current_min\n",
    "            self.no_improvement = 0\n",
    "        else:\n",
    "            self.no_improvement += 1\n",
    "            \n",
    "        return self.no_improvement >= self.patience\n",
    "\n",
    "class BOStopper:\n",
    "    def __init__(self, conv_patience=10, conv_tol=1e-8,\n",
    "                 ci_width=0.2, ci_patience=10, max_iter=100):\n",
    "        self.conv_stopper = ConvergenceStopper(conv_patience, conv_tol)\n",
    "        # self.ci_stopper = ConfidenceIntervalStopper(ci_width, ci_patience)\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def __call__(self, result):\n",
    "        # 最大迭代次数检查\n",
    "        if len(result.x_iters) >= self.max_iter:\n",
    "            return True\n",
    "            \n",
    "        # 收敛检查\n",
    "        if self.conv_stopper(result):\n",
    "            return True\n",
    "        \n",
    "        # 置信区间检查\n",
    "        # if self.ci_stopper(result):\n",
    "        #     return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "\n",
    "def bayesian_opt(Y, X, W, kernel, c_upper): \n",
    "    # Define the hyperparameter space\n",
    "    STD_C = Real(low=1e-3, high=c_upper, prior='log-uniform', name='C')\n",
    "    dim_class_weight_1 = Real(low=0.1, high=2.0, prior='uniform', name='class_weight_1')\n",
    "    dim_class_weight_neg1 = Real(low=0.1, high=2.0, prior='uniform', name='class_weight_neg1')\n",
    "\n",
    "\n",
    "    dimensions = [STD_C, dim_class_weight_1, dim_class_weight_neg1]\n",
    "\n",
    "    # Define the target score function\n",
    "    @use_named_args(dimensions=dimensions)\n",
    "    def objective_1(**params):\n",
    "        class_weight = {1: params['class_weight_1'], -1: params['class_weight_neg1']}\n",
    "        clf = SVC(C=params['C'], kernel=kernel, class_weight=class_weight)\n",
    "        # return score  # We negate because we want to maximize accuracy\n",
    "    \n",
    "        clf.fit(X_train, W_train)\n",
    "        score = clf.score(X_test, W_test)\n",
    "        # ess = estimate_ess(Y, W, X, alpha, support_indices)\n",
    "        return -score\n",
    "\n",
    "    @use_named_args(dimensions=dimensions)\n",
    "    def objective_2(**params):\n",
    "        class_weight = {1: params['class_weight_1'], -1: params['class_weight_neg1']}\n",
    "        clf = SVC(C=params['C'], kernel=kernel, class_weight=class_weight)\n",
    "        # return score  # We negate because we want to maximize accuracy\n",
    "    \n",
    "        clf.fit(X_test, W_test)\n",
    "        score = clf.score(X_train, W_train)\n",
    "        # ess = estimate_ess(Y, W, X, alpha, support_indices)\n",
    "        return -score\n",
    "\n",
    "    def crossfitting(result, Y, X, W):\n",
    "        best_params = result.x\n",
    "        best_score = result.fun  # Negate to get the actual score\n",
    "\n",
    "        C = best_params[0]\n",
    "        class_weight = {1: best_params[1], -1: best_params[2]}\n",
    "\n",
    "        best_model = SVC(C=C, kernel=kernel)\n",
    "        best_model.fit(X, W)\n",
    "        support_indices = best_model.support_\n",
    "        alpha = np.abs(best_model.dual_coef_[0])\n",
    "        ATE = estimate_ate(Y, W, X, alpha, support_indices)\n",
    "        DIM = estimate_diff(Y, W, X, alpha, support_indices)\n",
    "        ESS = estimate_ess(Y, W, X, alpha, support_indices)\n",
    "        STD = compute_wnayman(Y, W, X, alpha, support_indices)\n",
    "        \n",
    "        print(\"Best Hyperparameters:\", best_params)\n",
    "        print(\"Best Cross-Validation Score:\", best_score)\n",
    "        print(\"ATE:\", ATE)\n",
    "        print(\"STD:\", STD)\n",
    "\n",
    "        class_weight = best_params[1]/best_params[2]\n",
    "\n",
    "        return(ATE, DIM, ESS, C, class_weight, STD)\n",
    "    \n",
    "    # Initialize the Bayesian Optimization\n",
    "    n_initial_points = 5\n",
    "    # n_calls = 50\n",
    "\n",
    "    # 定义综合停止器\n",
    "    stopper_1 = BOStopper(\n",
    "        conv_patience=10,\n",
    "        conv_tol=1e-6,\n",
    "        # ci_width=0.2,\n",
    "        # ci_patience=10,\n",
    "        max_iter=100\n",
    "    )\n",
    "    \n",
    "    stopper_2 = BOStopper(\n",
    "        conv_patience=10,\n",
    "        conv_tol=1e-6,\n",
    "        # ci_width=0.2,\n",
    "        # ci_patience=10,\n",
    "        max_iter=100\n",
    "    )\n",
    "\n",
    "    Y_train, Y_test, X_train, X_test, W_train, W_test = train_test_split(Y, X, W, test_size=0.5, random_state=42)\n",
    "\n",
    "    result_1 = gp_minimize(objective_1, dimensions, n_initial_points=n_initial_points, callback=[stopper_1], random_state=42, verbose=True)\n",
    "    result_1 = crossfitting(result_1, Y_test, X_test, W_test)\n",
    "\n",
    "    result_2 = gp_minimize(objective_2, dimensions, n_initial_points=n_initial_points, callback=[stopper_2], random_state=42, verbose=True)\n",
    "    result_2 = crossfitting(result_2, Y_train, X_train, W_train)\n",
    "\n",
    "    ATE = (result_1[0] + result_2[0])/2\n",
    "    DIM = (result_1[1] + result_2[1])/2\n",
    "    ESS = result_1[2] + result_2[2]\n",
    "    C = (result_1[3] + result_2[3])/2\n",
    "    class_weight = (result_1[4] + result_2[4])/2\n",
    "    STD = (result_1[5] + result_2[5])/2\n",
    "\n",
    "    return(ATE, DIM, ESS, C, class_weight, STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 1.3504\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0788\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.2693\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.3071\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.5358\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.0002\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2619\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1436\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3166\n",
      "Function value obtained: -0.1690\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3100\n",
      "Function value obtained: -0.1690\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3087\n",
      "Function value obtained: -0.1690\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3727\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3296\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3664\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.3254\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.8520\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.8301\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.2854\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2827\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4039\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "条件抽样方差: 1.8946815482279982\n",
      "Best Hyperparameters: [0.006259548184287541, 0.4485261007457112, 1.581412900518262]\n",
      "Best Cross-Validation Score: -0.831\n",
      "ATE: 43.02255009981553\n",
      "STD: 1.3764743180415675\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 1.5548\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0638\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0938\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.2533\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.3867\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5072\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2720\n",
      "Function value obtained: -0.1500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5114\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4499\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2912\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3306\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.7249\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5881\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4104\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.6284\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3973\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3418\n",
      "Function value obtained: -0.1500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4361\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4142\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3909\n",
      "Function value obtained: -0.1500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "条件抽样方差: 2.231395857218649\n",
      "Best Hyperparameters: [0.006259548184287541, 0.4485261007457112, 1.581412900518262]\n",
      "Best Cross-Validation Score: -0.85\n",
      "ATE: 43.81647777182735\n",
      "STD: 1.4937857467584328\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 3.6981\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0778\n",
      "Function value obtained: -0.8360\n",
      "Current minimum: -0.8360\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.4348\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8360\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 1.9119\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8360\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 2.5262\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8360\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2998\n",
      "Function value obtained: -0.8390\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.6197\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.2882\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3025\n",
      "Function value obtained: -0.1690\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2975\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3721\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.7797\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2885\n",
      "Function value obtained: -0.1690\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2825\n",
      "Function value obtained: -0.1690\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.7283\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4209\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.5960\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2828\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5660\n",
      "Function value obtained: -0.1690\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.7784\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8390\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "条件抽样方差: 1.8907991218454945\n",
      "Best Hyperparameters: [0.006080446714793664, 1.0260501317423958, 0.21276019368038807]\n",
      "Best Cross-Validation Score: -0.839\n",
      "ATE: 42.8527841853479\n",
      "STD: 1.3750633155769572\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 5.7118\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0888\n",
      "Function value obtained: -0.8410\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.1386\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 2.3098\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 1.7137\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2385\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.7873\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4029\n",
      "Function value obtained: -0.8490\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.2710\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2394\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.4133\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.6055\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2578\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4460\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4079\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4772\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.6413\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.3248\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.6805\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.8446\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "条件抽样方差: 2.2355075429972744\n",
      "Best Hyperparameters: [0.03918194347141743, 0.4485261007457112, 1.581412900518262]\n",
      "Best Cross-Validation Score: -0.85\n",
      "ATE: 43.521360789037374\n",
      "STD: 1.4951613769079493\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 4.5488\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.1367\n",
      "Function value obtained: -0.8250\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 1.0392\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 2.7913\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 4.0390\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3873\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3912\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.5219\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.3792\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2886\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.3664\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8310\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.5838\n",
      "Function value obtained: -0.8320\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.1079\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.7151\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.9150\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.8328\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.2042\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2583\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.7089\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3678\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3324\n",
      "Function value obtained: -0.8310\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4280\n",
      "Function value obtained: -0.8250\n",
      "Current minimum: -0.8320\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "条件抽样方差: 1.8995745381823046\n",
      "Best Hyperparameters: [0.954288425298361, 1.3130888546803332, 0.7225733547969269]\n",
      "Best Cross-Validation Score: -0.832\n",
      "ATE: 43.344189685021945\n",
      "STD: 1.378250535346279\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 6.2433\n",
      "Function value obtained: -0.8500\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.1267\n",
      "Function value obtained: -0.8080\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.1585\n",
      "Function value obtained: -0.8460\n",
      "Current minimum: -0.8500\n",
      "Iteration No: 4 started. Evaluating function at random point.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kernel \u001b[38;5;129;01min\u001b[39;00m kernels:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m c_upper \u001b[38;5;129;01min\u001b[39;00m c_uppers:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         result = \u001b[43mbayesian_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_upper\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     40\u001b[39m         results[c_upper].append(result)\n\u001b[32m     43\u001b[39m     data = results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 199\u001b[39m, in \u001b[36mbayesian_opt\u001b[39m\u001b[34m(Y, X, W, kernel, c_upper)\u001b[39m\n\u001b[32m    196\u001b[39m result_1 = gp_minimize(objective_1, dimensions, n_initial_points=n_initial_points, callback=[stopper_1], random_state=\u001b[32m42\u001b[39m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    197\u001b[39m result_1 = crossfitting(result_1, Y_test, X_test, W_test)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m result_2 = \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstopper_2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m result_2 = crossfitting(result_2, Y_train, X_train, W_train)\n\u001b[32m    202\u001b[39m ATE = (result_1[\u001b[32m0\u001b[39m] + result_2[\u001b[32m0\u001b[39m])/\u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\gp.py:281\u001b[39m, in \u001b[36mgp_minimize\u001b[39m\u001b[34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    274\u001b[39m     base_estimator = cook_estimator(\n\u001b[32m    275\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGP\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    276\u001b[39m         space=space,\n\u001b[32m    277\u001b[39m         random_state=rng.randint(\u001b[32m0\u001b[39m, np.iinfo(np.int32).max),\n\u001b[32m    278\u001b[39m         noise=noise,\n\u001b[32m    279\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[43m=\u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace_constraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspace_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\base.py:332\u001b[39m, in \u001b[36mbase_minimize\u001b[39m\u001b[34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[32m    331\u001b[39m     next_x = optimizer.ask()\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     next_y = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m     result = optimizer.tell(next_x, next_y)\n\u001b[32m    334\u001b[39m     result.specs = specs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\utils.py:779\u001b[39m, in \u001b[36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    776\u001b[39m arg_dict = {dim.name: value \u001b[38;5;28;01mfor\u001b[39;00m dim, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dimensions, x)}\n\u001b[32m    778\u001b[39m \u001b[38;5;66;03m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m objective_value = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43marg_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m objective_value\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 143\u001b[39m, in \u001b[36mbayesian_opt.<locals>.objective_2\u001b[39m\u001b[34m(**params)\u001b[39m\n\u001b[32m    140\u001b[39m clf = SVC(C=params[\u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m], kernel=kernel, class_weight=class_weight)\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# return score  # We negate because we want to maximize accuracy\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m score = clf.score(X_train, W_train)\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# ess = estimate_ess(Y, W, X, alpha, support_indices)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:250\u001b[39m, in \u001b[36mBaseLibSVM.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[LibSVM]\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    249\u001b[39m seed = rnd.randint(np.iinfo(\u001b[33m\"\u001b[39m\u001b[33mi\u001b[39m\u001b[33m\"\u001b[39m).max)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;28mself\u001b[39m.shape_fit_ = X.shape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:328\u001b[39m, in \u001b[36mBaseLibSVM._dense_fit\u001b[39m\u001b[34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[39m\n\u001b[32m    314\u001b[39m libsvm.set_verbosity_wrap(\u001b[38;5;28mself\u001b[39m.verbose)\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[32m    318\u001b[39m (\n\u001b[32m    319\u001b[39m     \u001b[38;5;28mself\u001b[39m.support_,\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m.support_vectors_,\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m._n_support,\n\u001b[32m    322\u001b[39m     \u001b[38;5;28mself\u001b[39m.dual_coef_,\n\u001b[32m    323\u001b[39m     \u001b[38;5;28mself\u001b[39m.intercept_,\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m._probA,\n\u001b[32m    325\u001b[39m     \u001b[38;5;28mself\u001b[39m._probB,\n\u001b[32m    326\u001b[39m     \u001b[38;5;28mself\u001b[39m.fit_status_,\n\u001b[32m    327\u001b[39m     \u001b[38;5;28mself\u001b[39m._num_iter,\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m ) = \u001b[43mlibsvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass_weight_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28mself\u001b[39m._warn_from_fit_status()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define the dataset and hyperparameter space\n",
    "num_datasets = 100\n",
    "simulation_results_A = {n: [] for n in range(num_datasets)}\n",
    "\n",
    "\n",
    "kernels = ['linear']\n",
    "# pi_range = np.linspace(0.0, 1.0, 11)\n",
    "\n",
    "# pi_range = [0.0]\n",
    "# results = {pi: [] for pi in pi_range}\n",
    "\n",
    "\n",
    "c_uppers = [1e-2, 1e-1, 1e+0]\n",
    "\n",
    "results = {c_upper: [] for c_upper in c_uppers}\n",
    "\n",
    "with open('../results/rbf/simu_B2_w_100_2000_f.json', 'r') as f:\n",
    "    data_str = f.read()\n",
    "\n",
    "\n",
    "results = json.loads(data_str)\n",
    "\n",
    "# results['1.0'] = []\n",
    "# results['10.0'] = []\n",
    "# results['100.0'] = []\n",
    "\n",
    "for n in range(num_datasets):\n",
    "    # simulate_data = pd.read_csv('../data_A_2000/data_scenario_G_n_500_dataset_{}.csv'.format(n))\n",
    "    simulate_data = pd.read_csv('../data_B3_2000/dataset_{}.csv'.format(n))\n",
    "\n",
    "    X = simulate_data.drop(columns=['T', 'Y'])\n",
    "    T = simulate_data['T']\n",
    "    Y = simulate_data['Y']\n",
    "\n",
    "    W = 2 * T - 1\n",
    "\n",
    "    for kernel in kernels:\n",
    "        for c_upper in c_uppers:\n",
    "            result = bayesian_opt(Y, X, W, kernel, c_upper) \n",
    "\n",
    "            results[c_upper].append(result)\n",
    "\n",
    "\n",
    "        data = results\n",
    "\n",
    "        data_str = json.dumps(data, cls=NumpyEncoder, indent=4)\n",
    "\n",
    "        with open(f'../results/{kernel}/simu_B3_w_100_2000_f.json', 'w') as f:\n",
    "            f.write(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# import json\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# with open('../results/rbf/simu_B_2.0_w_20.json', 'r') as f:\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     data_str = f.read()\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# results = json.loads(data_str)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m)\n\u001b[32m      8\u001b[39m c_upper = []\n\u001b[32m      9\u001b[39m kernel_ate_estimates = []\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('../results/rbf/simu_B_2.0_w_20.json', 'r') as f:\n",
    "    data_str = f.read()\n",
    "\n",
    "results = json.loads(data_str)\n",
    "print(results)\n",
    "\n",
    "c_upper = []\n",
    "kernel_ate_estimates = []\n",
    "for c_uppers, models in results.items():\n",
    "    for model in models:\n",
    "        c_upper.append(float(c_uppers))\n",
    "        kernel_ate_estimates.append(float(model[0]))\n",
    "\n",
    "data = pd.DataFrame({'c_upper': c_upper, 'ATE': kernel_ate_estimates})\n",
    "\n",
    "# 分组\n",
    "grouped_data = data.groupby('c_upper')['ATE'].apply(list).tolist()\n",
    "\n",
    "# 计算每个分组的平均值和方差\n",
    "grouped_stats = []\n",
    "for group in grouped_data:\n",
    "    mean = np.mean(group)\n",
    "    variance = np.var(group, ddof=1)  # 使用样本方差\n",
    "    grouped_stats.append({'mean': mean, 'variance': variance})\n",
    "\n",
    "# 打印结果\n",
    "for i, stats in enumerate(grouped_stats):\n",
    "    print(f\"c_upper: 1e+{i+3}, Mean: {stats['mean']}, Variance: {stats['variance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##PLOT ATE\n",
    "def plot_ate(results):\n",
    "\n",
    "    kernel = 'rbf'\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3,figsize=(12, 4))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "    i= 0\n",
    "\n",
    "    # 过滤出当前kernel的所有模型\n",
    "    i = i  \n",
    "    c_upper = []\n",
    "    kernel_ate_estimates = []\n",
    "    for c_uppers, models in results.items():\n",
    "        for model in models:\n",
    "            c_upper.append(float(c_uppers))\n",
    "            kernel_ate_estimates.append(float(model[0]))\n",
    "\n",
    "    data = pd.DataFrame({'c_upper': c_upper, 'ATE': kernel_ate_estimates})\n",
    "    grouped_data = data.groupby('c_upper')['ATE'].apply(list).tolist()\n",
    "    #print(sorted(set(pi)))\n",
    "    print(grouped_data)\n",
    "\n",
    "    # x_sticks = pi\n",
    "    x_values = [f\"$10^{{{int(np.log10(c))} }}$\" for c in sorted(set(c_upper))]\n",
    "    print(x_values)\n",
    "    # 绘制箱型图\n",
    "    axes[i].boxplot(grouped_data)\n",
    "    # axes[i].axhline(y=-0.4, color='r', linestyle='--', label='True ATE (A)')\n",
    "    axes[i].axhline(y=10, color='r', linestyle='--', label='True ATE (B)')\n",
    "    #axes[i].set_xscale('log')\n",
    "    axes[i].set_title(f'{kernel}')\n",
    "    #axes[i].set_xticks(x_sticks)  # 保持刻度位置不变\n",
    "    axes[i].set_xticklabels(x_values)\n",
    "    axes[i].set_xlabel('c_upper')\n",
    "    axes[i].set_ylabel('ATE')\n",
    "    axes[i].legend()\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    i = i  \n",
    "    c_upper = []\n",
    "    ESS = []\n",
    "    for c_uppers, models in results.items():\n",
    "        for model in models:\n",
    "            c_upper.append(float(c_uppers))\n",
    "            ESS.append(float(model[2]))\n",
    "\n",
    "    data = pd.DataFrame({'c_upper': c_upper, 'ESS': ESS})\n",
    "    grouped_data = data.groupby('c_upper')['ESS'].apply(list).tolist()\n",
    "    #print(sorted(set(pi)))\n",
    "    print(grouped_data)\n",
    "\n",
    "    # x_sticks = pi\n",
    "    x_values = [f\"$10^{{{int(np.log10(c))} }}$\" for c in sorted(set(c_upper))]\n",
    "    # 绘制箱型图\n",
    "    axes[i].boxplot(grouped_data)\n",
    "    axes[i].axhline(y=1000, color='r', linestyle='--', label='SS')\n",
    "    #axes[i].set_xscale('log')\n",
    "    axes[i].set_title(f'{kernel}')\n",
    "    #axes[i].set_xticks(x_sticks)  # 保持刻度位置不变\n",
    "    axes[i].set_xticklabels(x_values)\n",
    "    axes[i].set_xlabel('c_upper')\n",
    "    axes[i].set_ylabel('ESS')\n",
    "    axes[i].legend()\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    # i = i  \n",
    "    # c_upper = []\n",
    "    # DIM = []\n",
    "    # for c_uppers, models in results.items():\n",
    "    #     for model in models:\n",
    "    #         c_upper.append(float(c_uppers))\n",
    "    #         DIM.append(float(model[1]))\n",
    "    \n",
    "\n",
    "    # data = pd.DataFrame({'c_upper': c_upper, 'DIM': DIM})\n",
    "    # grouped_data = data.groupby('c_upper')['DIM'].apply(list).tolist()\n",
    "    # print(grouped_data)\n",
    "\n",
    "    # x_values = [f\"$10^{{{int(np.log10(c))} }}$\" for c in sorted(set(c_upper))]\n",
    "    # # 绘制箱型图\n",
    "    # axes[i].boxplot(grouped_data)\n",
    "    # axes[i].set_title(f'{kernel}')\n",
    "    # axes[i].set_xticklabels(x_values)\n",
    "    # axes[i].set_xlabel('c_upper')\n",
    "    # axes[i].set_ylabel('DIM')\n",
    "    # axes[i].legend()\n",
    "\n",
    "    i = i\n",
    "    c_upper = []\n",
    "    STD = []\n",
    "    for c_uppers, models in results.items():\n",
    "        for model in models:\n",
    "            c_upper.append(float(c_uppers))\n",
    "            STD.append(float(model[5]))\n",
    "    \n",
    "    data = pd.DataFrame({'c_upper': c_upper, 'STD': STD})\n",
    "    grouped_data = data.groupby('c_upper')['STD'].apply(list).tolist()\n",
    "    print(grouped_data)\n",
    "\n",
    "    x_values = [f\"$10^{{{int(np.log10(c))} }}$\" for c in sorted(set(c_upper))]\n",
    "    # 绘制箱型图\n",
    "    axes[i].boxplot(grouped_data)\n",
    "    axes[i].set_title(f'{kernel}')\n",
    "    axes[i].set_xticklabels(x_values)\n",
    "    axes[i].set_xlabel('c_upper')\n",
    "    axes[i].set_ylabel('STD')\n",
    "    axes[i].legend()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.118873938066315, 12.08615047488189, 10.923756992012699, 10.538107113204433, 12.220051743737898, 14.266066411533231, 12.42327358765408, 13.020709160147362, 11.072044079524588, 14.897187180306545, 13.803536063969418, 13.526516832917281, 11.486496636695577, 13.700349965035102, 12.091826725390376, 12.615975892943908, 13.827903950883979, 14.488713970653691, 12.177913470299146, 12.864330955669487, 12.183725072543723, 7.61530722244342, 13.4796448626076, 10.637827080003987, 12.125816759007549, 10.57346673953495, 12.853470276617301, 11.844320428345156, 13.353923905568323, 11.701288949103699, 10.842616121643715, 15.773724241941807, 9.043375520916598, 14.799795933818416, 14.512492498689483, 12.992282671827226, 9.806113497361054, 10.685371023504288, 12.014069188129938, 9.381326396509508, 10.669610559040635, 10.87878179710816, 10.106263470486383, 10.233131399931352, 11.549820161714806, 11.661343628548877, 13.415774027153319, 10.944611199311566, 13.669051233002278, 14.386381322926255, 12.193776784522484, 12.195502839060111, 13.83675828772735, 11.593119089344157, 12.496270141213529, 12.74416289498133, 14.298059073308636, 12.390984683611308, 11.436015978482772, 11.958695464192232, 15.255182723199312, 12.401763264996532, 15.043587158036729, 11.310336194011327, 10.573843784125458, 13.48747865108578, 11.269846223497083, 14.21864364478624, 9.532148240112363, 11.288227780564327, 13.064675636823992, 13.892898212037238, 9.530321274274982, 10.608620859554108, 14.046270839306032, 10.648162462357249, 15.782949548281522, 13.32260543565927, 14.169659363298678, 12.645440119005798, 12.618475357102298, 13.997272211204745, 12.815938061712231, 11.768905608371512, 11.682206200679033, 14.835270602933974, 14.50978628768155, 13.81507385761985, 13.477648146021977, 9.630086499581509, 13.618886280889697, 12.077619791295234, 12.856586310133565, 11.847905784051761, 13.385447658050438, 13.770016425126045, 12.431632375962607, 10.54271936949037, 12.70104619891984, 10.676507754953349]]\n",
      "['$10^{3 }$']\n",
      "[[862.6552708740049, 874.4519453982374, 884.2899816184587, 884.741671010453, 861.9449300972128, 878.9422139072553, 892.6605166776399, 843.207176141962, 854.0303413871294, 843.7542351932025, 865.6490770322964, 867.088772952196, 863.564051765569, 873.6119624100562, 898.6028436181241, 869.0738413336685, 867.456069813702, 866.7713404705188, 887.299344154181, 891.0977902922065, 881.172504677509, 868.3016871829004, 878.1543827117483, 890.874919163752, 873.8226000613215, 870.9908561729326, 863.0958541056793, 905.8152541992578, 884.1175829796161, 893.0531859475393, 876.8672966364733, 865.7513438321535, 881.750038612364, 859.7482163422635, 866.9540626887037, 863.8577255434768, 872.1407154727237, 899.6608401586634, 926.6712024210445, 868.1108525684764, 883.0749421628755, 876.927599816705, 868.3391441250806, 882.8315945660681, 886.7477137925016, 866.2457656042919, 864.7332088567628, 874.9362963825253, 864.8912423609107, 873.9000766453231, 908.9336095233625, 878.8509855252855, 858.9680650208712, 886.600358409936, 849.2196248240609, 870.9171287504197, 867.7098054778479, 899.7174550978397, 879.748261788128, 905.9578944239331, 865.5363957698787, 870.8043355744578, 862.5118412015513, 867.5488868514419, 903.4861948976202, 872.2611216205523, 870.9258983001203, 872.5329345793247, 886.0267188731414, 880.7691649550243, 856.9035520937999, 866.014268871802, 870.6795774999182, 878.9432123970809, 862.133275220066, 884.6284535528315, 861.3527856450256, 876.2485316998236, 872.4941355761232, 882.5499444830346, 881.2495429358333, 890.9003608105327, 877.164047116072, 883.801188297529, 884.327010390863, 837.0040567324629, 938.3349954696024, 867.7748442637334, 931.6632154088124, 872.0936187935519, 855.8923913693994, 880.247146276482, 881.0508205161137, 871.2676397437701, 871.0026346286429, 889.2361015032177, 875.5795251338556, 882.9744364089195, 851.0386976084379, 863.8312517009299]]\n",
      "[[0.9275609368793952, 0.9300434961091099, 0.8790549218097421, 0.9222819655055698, 0.9056924255258525, 0.9103621956680139, 0.8890978758902726, 0.9500090871724758, 0.9169256519084686, 0.9221141207509299, 0.9205715070102107, 0.9012663203562989, 0.9455514789001713, 0.9136085883555987, 0.9445259744060178, 0.9079666130999002, 0.9235329224027911, 0.9235955040520565, 0.9007926788008316, 0.9454923338549512, 0.9401977793828882, 0.9096597814839864, 0.94342083142725, 0.9364699641899009, 0.9072727789387407, 0.9015043030682872, 0.9095979391302123, 0.9163964541160516, 0.9045360183531864, 0.9123062007778123, 0.8968813500778583, 0.8911848446123427, 0.8994823761420221, 0.9300521679804812, 0.9180200966892591, 0.9199506216780866, 0.9203804400553325, 0.8794149277061294, 0.8828516676830285, 0.9199282988462553, 0.9388958283747737, 0.9185521935689371, 0.9399539876200824, 0.906876964571282, 0.9186283655159109, 0.9068841729763447, 0.9244461364279621, 0.8915662531537479, 0.8856855657258536, 0.9058602930454285, 0.9034629502813649, 0.8906046125968111, 0.9166620955235292, 0.925077383830732, 0.931003000263438, 0.8860769981452525, 0.9073740611987813, 0.8854095532595412, 0.9037489100975153, 0.8902176523242449, 0.9028818680993416, 0.8910752983482666, 0.9458129227827103, 0.911177018396621, 0.8847175735116835, 0.9281614349993458, 0.9224610866836863, 0.8907751795677536, 0.8711658050615901, 0.9246886112895202, 0.9052458549576902, 0.9252720245362889, 0.9236725049095384, 0.9479237000942151, 0.9275209487179384, 0.9188182880965599, 0.9230149543701884, 0.9025820191141518, 0.9226575631045157, 0.9163558995097246, 0.9057875471944214, 0.9043882563755492, 0.8860026946948415, 0.9006119095418587, 0.8783961192225997, 0.9297707443742511, 0.8546644609579835, 0.9479005204744105, 0.8993584217162469, 0.8997501667450765, 0.9090177291171406, 0.9171662650663776, 0.9098467454392201, 0.8710437673861096, 0.910408688420643, 0.8923945033324889, 0.9094817099841408, 0.9092194696688993, 0.9330981188522274, 0.9115672844831444]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmaat\\AppData\\Local\\Temp\\ipykernel_2780\\2332384574.py:111: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  axes[i].legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ate(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
